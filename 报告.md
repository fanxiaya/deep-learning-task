##你是怎样获取bert-base-chinese模型的?
直接调用huggingface的transformers库里的api,开了魔法应该就可以直接用上了
```python
model = AutoModelForSequenceClassification.from_pretrained("bert-base-chinese", num_labels=3)
```
后续模型会存在wsl系统的一个目录下,在我的设备上是:
```
\wsl.localhost\Ubuntu-24.04\home\xiaya\.cache\huggingface\hub\models--bert-base-chinese
```

##你获取数据集的方式,为什么获取该数据集
kaggle网站下载数据集[Amazon Reviews Multi](https://www.kaggle.com/datasets/mexwell/amazon-reviews-multi)
这个数据集包含了亚马逊购物网站上相当多的 用户对商品的评价.符合任务要求的**商品评价情感倾向分类**的需要就直接拿来用了

##你是否对数据集进行了预处理优化？如果是，请写出你的优化手段以及用你的理解告诉我们为什么要进行预处理。
- 原数据集包括多种语言以及很多的多余字段,只保留了中文评论(review_body)字段和stars字段
- stars字段的值从1~5分布,对于好中差的分类标准,我把stars值为1的映射到差评,2和3映射到中,4,5映射到好评,比较符合一般的习惯
- 原数据集的emoji含量相当少,直接当脏数据处理了,并将原数据集中字数过少的评论对于的数据直接舍弃,以及原数据集字段有缺失或格式不符的数据直接舍弃

- **对于预处理的理解**:
  1.模型对输入的文本进行分词处理,预处理数据可以在分词这一步给模型足够有效的内容,而不被无效的数据干扰.
  2.对于数据对应的标签:
  自己在训练的时候,有一段时间一直持续的训练新数据,最终的准确率没有明显的变化.所以重新手动的评估了小部分数据对应的标签(大概6000条,和一次训练的数据条数差不多),最后的准确率提升也不算明显.
  **个人认为**是商品评论的原评论内容的原因,很多评论换自己来也很难判断是好中差里的哪一档,感觉训练正确率不高是三分类的局限和用户评论本身(评论本身难以分辨是好中差的哪一种)一起导致的,如果换成原数据集里的stars(1~5 5种值)可能正确率会更高
  
##你采取的优化方式，并详细讲解为什么这种方式可以优化模型以及其优化逻辑
- 数据集结构调整: 因为只有一张A GeForce MX550,原数据集的训练集大约又有20万条,所有把训练集均分成了多个小份数据集来分次训练
统计了一下数据里三分类的占比,大约在0.2:0.4:0.4. 训练.在这个情况下,**占比为0.2的差评标签**训练正确率较低,只有百分之五十多,所以后面调整了每小份的数据集的各个标签占比为0.7:1.0:1.0.由于各种标签的数据占比变得更加平均,调整过后差评对应的正确率提升较多,虽然别的标签正确率有所下降,但总体正确率上升
- 训练参数:
问AI要了个推荐参数,自己也去了解了对应参数的含义继续调整和重新训练,但是感觉对模型预测准确率效果的提升不是很明显,主要是对训练时间和显存的占用上有改变

##在实验过程中，你是否遇见了优化策略反而负优化之类的问题，请记录下来
- 没有遇到,只有调整训练参数不断训练新数据时,正确率基本保持不变的效果

##模型优化前后准确率的记录
- 训练后的模型
  - 总体准确率：0.7166
  - 分标签：label0=0.6830（对应差评），label1=0.6745（对应中评），label2=0.7755(对应好评）

- bert-base-chinese
  - 总体准确率：0.3880
  - 分标签：label0=0.0000，label1=0.0465，label2=0.9235

##你对优化后的模型在验证集上的准确率有什么样的结论？
- 总体提升显著：优化后的模型总体准确率达到 0.7166，相比直接使用未微调的 `bert-base-chinese` 的 0.3880 提升约 32.9 个百分点
- 分标签表现差异：对“好评”（label2）效果最好（0.7755），对“差评”（label0）与“中评”（label1）相近且略低（0.6830 / 0.6745）。这与实际语料特性一致：好评用语更集中、信号更强；中差评更容易与中性/模糊表达混淆
- 基线暴露的问题：未微调的 `bert-base-chinese` 在 label0/1 上失效（0.0000 / 0.0465），显示仅靠通用预训练、缺少领域学习时，模型难以区分负向与中性类别
- 结论：当前模型已具备可用的三分类能力，尤其对“好评”最稳健；“差评”和"中评"的分辨仍相对困难

[github仓库](https://github.com/fanxiaya/deep-learning-task)





